# -*- Mode: sh; sh-basic-offset:2 ; indent-tabs-mode:nil -*-
#
# Copyright (c) 2014-2016 Los Alamos National Security, LLC.  All rights
#                         reserved.
# $COPYRIGHT$
#
# Additional copyrights may follow
#
# $HEADER$
#

#----------------------------------------------------------------------------
# run_setup - common setup for hio tests
# Source this file from each test script.
#
# Env vars used for input:
#   BUILD_TREE - location of HIO build tree, defaults to $PWD/..
#
# BASH variables set that can be used by test script:
#        root - data root for test, created or emptied
#        size - gross size of IO, per rank t|s|m|l|x|y|z
#       ranks - number of MPI ranks
#    verbose_lev - xexec2 verbosity level
#   debug_lev - xexec2 debug level
#   HIO_TEST_ROOT - if not set, will be set to default data root string
#
# BASH functions that can be called by the test script:
#   clean_roots - creates or empties out specified data roots
#           cmd - logs and runs a command
#           msg - logs a message
#         myrun - issues mpirun or aprun command with -n specified
#
#----------------------------------------------------------------------------
synexit() {
  echo ""
  if [[ -n $* ]]; then echo "Error: $*"; echo ""; fi
  echo "run_setup - common setup for hio tests"
  echo ""
  echo "  Syntax:"
  echo "    $0"
  echo "        [-s <size>]]"
  echo "        [-r <num_ranks>]"
  echo "        [-n <num_nodes>]"
  echo "        [-p <ppn>]"
  echo "        [-j <tpp>]"
  echo "        [-v <verbose_level>]"
  echo "        [-d <debug_level>]"
  echo "        [-b] [-c] [-a] [-q]"
  echo "        [-w <dw_alloc>]"
  echo "        [-x <dw_alloc_pct>]"
  echo "        [-k knl|haswell]" 
  echo "        [-m <msub args>]"
  echo "        [-u <uber command and args>]"
  echo ""
  echo "  Options:"
  echo "    -s <size>         Per rank run size u|t|s|m|l|x|y|z  (default s)"
  echo "       <totsz>[,<blksz>][,<nseg>]  where:"
  echo "                      totsz - total size per rank in MiB"
  echo "                      blksz - size of each write/read in KiB"
  echo "                      nseg - number of segments (not used by all tests)"
  echo "    -r <num_ranks>    Number of MPI ranks.  Default is all allocated"
  echo "                      PEs or 2 on Mac OS"
  echo "    -n <num_nodes>    Number of nodes.  Default is all allocated nodes"
  echo "                      or 2 or 1 on Mac OS"
  echo "    -p <ppn>          PEs per node.  If specified with -n and -r, must agree"
  echo "    -j <tpp>          Threads per processor, only valid on Cray, default 1"
  echo "    -v <verbose_lev>  Verbosity level for xexec2, default 1"
  echo "    -d <debug_lev>    Debug level for xexec2, default 0"
  echo "    -b                Submit batch job with these options"
  echo "    -c                Chain jobs - make this job dependant on previous job"
  echo "    -a                Clean dirs After running"
  echo "    -q                Query data size. Output value like \"32GiB\" and exit"
  echo "    -w <dw_alloc>     DataWarp allocation policy 0=never, 1=static, 2=Moab"
  echo "                      3=DataWarp only (via Moab)" 
  echo "    -x <dw_alloc_pct> Multiply any requested allocation by this percentage."
  echo "       n<dw_nodes>    Or, if it starts with \"n\" request enough to allocate"
  echo "                      on that many DataWarp nodes based on granularity"
  echo "    -k knl|haswell    Adds :<type> to msub -l option, influences -p default"
  echo "    -m <msub_args>    Additional arguments for msub (use with -b)"
  echo "    -u <uber command and args>  Use to invoke a debugger (not to call a taxi)"
  echo ""
  echo "  Cornell Wright  cornell@lanl.gov"

  exit 8
}

#----------------------------------------------------------------------------
# Functions for run_setup and test scripts to use
#----------------------------------------------------------------------------
cmd() {
  echo "`date \"$datefmt\"` $host run_setup ---> $*"
  eval "$*"
  return $?
}

msglog=""
msg() {
  echo "`date \"$datefmt\"` $host run_setup: $*"
  if [[ -n $msglog ]]; then echo "`date \"$datefmt\"` $host run_setup: $*" >> $msglog; fi
}

errx() {
  msg "Error: $*; Exitting"
  exit 12
}

cvt() {
    if [[ $(( $1 / $cons_ti )) -gt 99 ]]; then echo "$(( $1 / $cons_ti )) Ti"
  elif [[ $(( $1 / $cons_gi )) -gt 99 ]]; then echo "$(( $1 / $cons_gi )) Gi"
  elif [[ $(( $1 / $cons_mi )) -gt 99 ]]; then echo "$(( $1 / $cons_mi )) Mi"
  elif [[ $(( $1 / $cons_ki )) -gt 99 ]]; then echo "$(( $1 / $cons_ki )) Ki"
  else echo "$1"
  fi
}

# Function to check max_rc and output a summary message
check_rc(){
  if [[ $max_rc > 0 ]]; then result="FAILURE"
  else result="SUCCESS"; fi
  jobend=`date "$datefmt"`
  echo "###############################################################################"
  echo "Start: $jobstart  End: $jobend  Test: $0 -s $size -n $nodes -r $ranks   RESULT: $result"
  echo "###############################################################################"
}

# Function to build run script and submit batch job if batch mode
batch_sub() {
  if [[ -z $dw_cap_override ]]; then
    # Save DataWarp required capacity with 5% + 1GiB  overhead and rounded up to next GiB
    dw_cap="$(( (($1 * 21 / 20 * $dw_alloc_pct / 100) + (1 * $cons_gi) + ($cons_gi - 1) ) / $cons_gi ))GiB"
  else
    dw_cap=$dw_cap_override
  fi 
  if [[ $query_size -eq 1 ]]; then
    echo $dw_cap
    exit 0
  fi
  msg "DataWarp Capacity: $dw_cap"
  if [[ $batch -gt 0 ]]; then
    rundir="$PWD/run"
    if [[ ! -d $rundir ]]; then cmd "mkdir -p $rundir"; fi
    lastjob="$rundir/last_jobid"

    # Ensure unique job name
    jobname=`date +%Y%m%d.%H%M%S.%N`
    jobsh="$rundir/job.$jobname.sh"
    while [[ -e $jobsh ]]; do
      msg "File $jobsh already exists, trying another"
      jobname=`date +%Y%m%d.%H%M%S.%N`
      jobsh="$rundir/job.$jobname.sh"
    done
    jobout="$rundir/job.$jobname.out"
    msglog="$rundir/job.$jobname.jobid"
    msg "Job $jobname Args: $args"

    echo "#! /bin/bash" > $jobsh
    proc_parm=""
    if [[ -n $proc_type ]]; then proc_parm=":$proc_type"; fi
    echo "#MSUB -l nodes=$nodes$proc_parm:ppn=$ppn" >> $jobsh
    walltime="4:00:00"
    #walltime=$(($nodes*1800/256+1803))
    echo "#MSUB -l walltime=$walltime" >> $jobsh
    echo "#MSUB -o $jobout -joe" >> $jobsh
    echo "#MSUB -d $PWD" >> $jobsh
    if [[ $dw_alloc_mode -ge 2 ]]; then
      echo "#DW jobdw access_mode=striped type=scratch capacity=$dw_cap" >> $jobsh
    fi
    echo "echo \"\`date \"$datefmt\"\` Job $jobname start\"" >> $jobsh
    echo "echo \"\"" >> $jobsh
    echo "echo \"$jobsh:\"" >> $jobsh
    echo "cat $jobsh" >> $jobsh
    echo "echo \"\"" >> $jobsh

    cparm=""
    if [[ $after -gt 0 ]]; then cparm="-a"; fi
    if [[ $tpp -ne 1 ]]; then cparm="$cparm -j $tpp"; fi
    echo "# Submit Args: $args" >>$jobsh
    echo "$0 -s $size $cparm -w $dw_alloc_mode -v $verbose_lev -d $debug_lev" >> $jobsh

    echo "echo \"\`date \"$datefmt\"\` Job $jobname   end\"" >> $jobsh

    mcmd="msub"
    IFS=","; hiovars="${!HIO_*},${!XEXEC_*}"; unset IFS
    hiovars=${hiovars#,}  # Remove any leading, trailing commas 
    hiovars=${hiovars%,}
    if [[ -n $hiovars ]]; then mcmd="$mcmd -v $hiovars"; fi
    if [[ -n $msub_arg ]]; then mcmd="$mcmd $msub_arg"; fi
    if [[ $chain -ne 0 ]]; then
      if [[ -r $lastjob ]]; then
        read lastjobid < $lastjob
        # Create array, extract last element for multi-id DataWarp jobs
        lastjobid=($lastjobid)
        lastjobid=${lastjobid[ ${#lastjobid[*]}-1 ]}
        mcmd="$mcmd -l depend=$lastjobid"
      else
        msg "Last jobid file \"$lastjob\" not readable, ignoring chain option"
      fi
    fi
    echo "----------------------------------------------------------------------" >> $msglog 
    echo "$host run_setup: $jobsh:" >> $msglog
    cat $jobsh >> $msglog
    echo "----------------------------------------------------------------------" >> $msglog 

    mcmd="$mcmd $jobsh"
    msg "---> $mcmd"
    msub_msg=`$mcmd 2>&1`

    shopt -s nocasematch
    if [[ $msub_msg == *error* || $msub_msg == *warn* || $msub_msg = *fail* ]]; then
      errx "msub error: $msub_msg"
    else
      jobid=${msub_msg#$'\n'}
      echo "$jobid" > $lastjob
      msg "Job $jobname ID: $jobid submitted"
    fi
    shopt -u nocasematch
    msglog=""
    if [[ $batch -eq 1 ]]; then exit 0; fi
  fi
}

# This string contains the logic to check, empty or create a test data root
# directory.  It needs to be executed on a compute node via aprun for datawarp.
# It's also used for locally accessible directories for the sake of consistency.
clean_cmd="
  if [[ -z \$0 ]]; then
    echo \"run_setup: zero length test root name0\"
    exit
  fi
  if [ -e \$0 ]; then
    if [ -d \$0 ]; then
      if [ ! -w \$0 ]; then
        echo \"run_setup: Unable to write to test root \$0\"
        exit
      else
        echo \"---> rm -fR \$0/*\"
        rm -fR \$0/*
      fi
    else
      echo \"run_setup: Test root \$0 exists and is not a directory\"
      exit
    fi
  else
    echo \"---> mkdir -p \$0\"
    mkdir -p \$0
  fi
"

# Function to clean data roots, i.e., create or empty them out
clean_roots() {
  if [[ ${OSTYPE:0:6} != "darwin" ]]; then
    # Running on a cluster - record some physical node information
    cmd "aprun -n $PBS_NUM_NODES -N 1 bash -c \"grep -i \\\"model name\\\" /proc/cpuinfo\" | sort | uniq -c"
    (export TERM=dumb; cmd "aprun -n 1 lstopo --of ascii -p")
    cmd "aprun -n 1 lstopo --of console -p"
  fi

  allroots=${1-$HIO_TEST_ROOTS}
  IFS=","; read -ra root <<< "$allroots"; unset IFS
  for r in "${root[@]}"; do
    shopt -s nocasematch
    if [[ "$r" == "dw" || "$r" == "datawarp" ]]; then
      clean=""
      if [[ -n $DW_JOB_STRIPED    ]]; then clean=$DW_JOB_STRIPED; fi
      if [[ -n $HIO_datawarp_root ]]; then clean=$HIO_datawarp_root; fi
      if [[ -n $clean ]]; then
        msg "Cleaning: \"$r\""
        msg "===> aprun bash -c \$clean_cmd $clean"
        aprun -n 1 -b bash -c "$clean_cmd" $clean
      fi
    elif [[ ${r:0:6} == "posix:" ]]; then
      msg "Cleaning: \"$r\""
      r=${r:6}
      # r=${r%"/"}
      # last=${r##*/}
      if [[ $r == ${r/test} ]]; then
        msg "Warning: skipping clean of non-test directory \"$r\""
      else
        bash -c "$clean_cmd" $r
      fi
    else
      errx "data root \"$r\" type not recognized."
    fi
    shopt -u nocasematch
  done
}

# function to invoke mpi on various platforms - sets max_rc
myrun() {
  if [[ $tpp -ne 1 ]]; then mympicmd="$mympicmd -j $tpp"; fi
  #msg "LD_LIBRARY_PATH=$LD_LIBRARY_PATH"
  #cmd "$mympicmd -n $ranks echo \"LD_LIBRARY_PATH=\$LD_LIBRARY_PATH\""
  #cmd "$mympicmd -n $ranks ls -l \${LD_LIBRARY_PATH%%:*}"
  #msg "PWD=$PWD"
  #cmd "ls -l $1"
  #cmd "$mympicmd -n $ranks ls -l $1"
  #export LD_DEBUG=all
  #export LD_DEBUG_OUTPUT=/lustre/scratch5/cornell/ld_debug/ldd.out
  cmd "$uber_cmd $mympicmd -n $ranks -N $ppn $*"
  rc=$?
  #unset LD_DEBUG
  #unset LD_DEBUG_OUTPUT
  max_rc=$((rc > max_rc ? rc : max_rc))
  return $rc
}

#----------------------------------------------------------------------------
# Parse arguments and other common setup
#----------------------------------------------------------------------------
datefmt="+%Y-%m-%d %H:%M:%S"
jobstart=`date "$datefmt"`
host=`hostname -s`
hostpre=${HOST:0:3}
max_rc=0
tpp=1
verbose_lev=1
debug_lev=0
batch=0
chain=0
after=0
dw_alloc_pct=100
proc_type=""
uber_cmd=""
query_size=0

size="s"
job_dir=""
# Platform specific defaults
if [[ ${OSTYPE:0:6} == "darwin" ]]; then
  mympicmd="mpirun"
  dw_alloc_mode=0
else
  size="m"
  type aprun > /dev/null 2>&1
  if [[ $? -eq 0 ]]; then
    # aprun available - must be a Cray
    mympicmd="aprun"
    size="m"
  else
    # aprun not available - use mpirun
    mympicmd="mpirun"
  fi
  if [[ $hostpre == "ga-" || $hostpre == "tt-" || $hostpre == "tr-" ]]; then
    dw_alloc_mode=2
  else
    dw_alloc_mode=0
  fi
fi

args="$0 $*"
while getopts "hs:r:n:p:j:v:d:bcw:ax:k:m:u:q" optname; do
  case $optname in
    h ) synexit;;
    s ) size=$OPTARG;;
    r ) ranks=$OPTARG;;
    n ) nodes=$OPTARG;;
    p ) ppn=$OPTARG;;
    j ) tpp=$OPTARG;;
    v ) verbose_lev=$OPTARG;;
    d ) debug_lev=$OPTARG;;
    b ) batch=1;;
    c ) chain=1;;
    w ) dw_alloc_mode=$OPTARG;;
    a ) after=1;;
    x ) dw_alloc_pct=$OPTARG;;
    k ) proc_type=$OPTARG;;
    m ) msub_arg=$OPTARG;;
    u ) uber_cmd=$OPTARG;;
    q ) query_size=1;;
   \? ) synexit "invalid option";;
  esac
done
shift $((OPTIND - 1 ))
if [[ -n $1 ]]; then synexit "extra parameters: \"$*\""; fi

case $proc_type in
  ""      ) ppn_def=2;;
  knl     ) ppn_def=68;;
  haswell ) ppn_def=32;;
  *       ) ppn_def=3;
            msg "Warning: processor type \"$proc_type\" not recognized, using anyway";;
esac

# Figure out nodes, ranks and ppn
until [[ -n $nodes && -n $ranks && -n $ppn ]]; do
  # Two parm cases -- calc third parm
  if   [[ -n $nodes && -n $ranks ]]; then   ppn=$(( ranks / nodes / tpp ))
  elif [[ -n $nodes && -n $ppn ]];   then ranks=$(( nodes * ppn * tpp   ))
  elif [[ -n $ranks && -n $ppn ]];   then nodes=$(( ranks / ppn / tpp   ))
  # Nodes only specified, determine ppn and iterate
  elif [[ -n $nodes ]]; then
    if   [[ -n $PBS_NUM_PPN ]]; then ppn=$PBS_NUM_PPN
    elif [[ -n $SLURM_NTASKS_PER_NODE ]]; then ppn=$SLURM_NTASKS_PER_NODE
    elif [[ ${OSTYPE:0:6} == "darwin" ]]; then ppn=2
    else                                       ppn=$ppn_def
    fi
  # Ranks only specified, determine nodes and iterate
  elif [[ -n ranks ]]; then
    if   [[ -n $PBS_NUM_NODES ]];         then nodes=$PBS_NUM_NODES
    elif [[ -n $SLURM_JOB_NUM_NODES ]];   then nodes=$SLURM_JOB_NUM_NODES
    elif [[ ${OSTYPE:0:6} == "darwin" ]]; then nodes=1
    elif [[ $ranks -eq 1 ]];              then nodes=1
    else                                       nodes=2
    fi
  # ppn only specified, determine nodes and iterate
  elif [[ -n ranks ]]; then
    if [[ ${OSTYPE:0:6} == "darwin" ]]; then nodes=1
    else                                     nodes=2
    fi
  # Nothing specified, determine ranks and iterate
  else
    if   [[ -n $PBS_NP ]]; then                ranks=$PBS_NP
    elif [[ -n $SLURN_NPROCS ]]; then          ranks=$SLURM_NPROCS
    elif [[ ${OSTYPE:0:6} == "darwin" ]]; then ranks=2
    else                                       ranks=4
    fi
  fi
done

if [[ $ranks -ne $((nodes * ppn * tpp)) ]]; then errx "ranks ($ranks) != nodes ($nodes) x ppn ($ppn) x tpp ($tpp)"; fi


# set some convenient constants
cons_ki=1024
cons_mi=$((1024*1024))
cons_gi=$((1024*1024*1024))
cons_ti=$((1024*1024*1024*1024))

#
# Set blksz, nblk, nseg, nblkpseg, segsz from size.  Only some tests use segs.
# If size starts with a digit, then it has format:
#   totsz(MiB) [, blksz(KiB)] [,nseg]
# Otherwise, size is a letter t,s,m,l,x,y,z implying those values.
# Defaults:
#   letter: s
#   blksz: 1KiB
#   nseg: 10
#
if [[ $size == [[:digit:]]* ]]; then
  szarr=(${size//,/ })
  if [[ -n ${szarr[3]} ]]; then errx "too many elements in size: \"$size\""; fi
  totsz=$(( $cons_mi * ${szarr[0]} ))
  blksz=$(( $cons_ki * ${szarr[1]-1} ))
  nseg=${szarr[2]-10}
  if [[ -n ${szarr[3]} ]]; then synexit "too many elements in size: \"$size\""; fi
else
  case $size in
    u ) blksz=$(( 32           )); totsz=$((  32           )); nseg=1;;
    t ) blksz=$((  1 * $cons_ki)); totsz=$((  10 * $cons_ki)); nseg=2;;
    s ) blksz=$(( 20 * $cons_ki)); totsz=$(( 160 * $cons_ki)); nseg=4;;
    m ) blksz=$((  1 * $cons_mi)); totsz=$(( 200 * $cons_mi)); nseg=8;;
    l ) blksz=$((  2 * $cons_mi)); totsz=$((   1 * $cons_gi)); nseg=16;;
    x ) blksz=$((  4 * $cons_mi)); totsz=$((   4 * $cons_gi)); nseg=24;;
    y ) blksz=$((  4 * $cons_mi)); totsz=$((   6 * $cons_gi)); nseg=28;;
    z ) blksz=$((  4 * $cons_mi)); totsz=$((   8 * $cons_gi)); nseg=32;;
    * ) synexit "invalid size $size";;
  esac
fi
nblk=$(($totsz / $blksz))
nblkpseg=$(($totsz / $nseg / $blksz))
segsz=$(($blksz * $nblkpseg))

if [[ ${dw_alloc_pct:0:1} -eq "n" ]]; then
  . $MODULESHOME/init/bash
  module load dws
  out=($(dwstat -b))
  dw_gran=${out[9]}
  dw_nodes=${dw_alloc_pct:1}
  # request (nodes - 1/2) * gran, rounded to GiB
  dw_cap_override="$(( ( ($dw_nodes * $dw_gran) - ($dw_gran / 2) ) / $cons_gi ))GiB"
  if [[ $query_size -eq 0 ]]; then
    msg "dw_gran: $((dw_gran/$cons_gi)) GiB  dw_nodes: $dw_nodes  dw_cap_override: $dw_cap_override GiB"
  fi
  # treat like -x 100 from here on
  dw_alloc_pct="100"
fi

# Check -w (dw_alloc_mode) option
case $dw_alloc_mode in
  0 ) ;;
  1 ) ;;
  2 ) ;;
  3 ) ;;
  * ) synexit "invalid -w option $dw_alloc_mode";;
esac

# Following commands for actually running, i.e., not batch submission
if [[ $batch -eq 0 ]]; then
  if [[ -n $PBS_JOBID ]]; then
    set | egrep "^PBS|^MOAB|^DW|^HOST|^HIO|^OSTYPE|^LD_LIBRARY_PATH"
    job_dir="/${PBS_JOBID%%.*}"
  fi
  if [[ -n $PBS_NODEFILE ]]; then
    echo ""
    cmd "cat $PBS_NODEFILE | sort | uniq | pr -t --columns 8"
  fi
  if [[ -n $DW_JOB_STRIPED ]]; then
    # awk program to parse a few things out of dwstat output
    c='
      BEGIN       {st='0'; frags=""; nodelist=""}
      /^ *sess /  {st="s"; sesshdr = $0}
      /^ *inst /  {st="i"; insthdr = $0}
      /^ *conf /  {st="c"; confhdr = $0}
      /^ *reg /   {st="r"; reghdr  = $0}
      /^ *activ / {st="a"; acthdr  = $0}
      /^ *frag /  {st="f"; fraghdr = $0}
      /^ *nss /   {st="n"; nsshdr  = $0}
      {
         nl = "\n## "
        nl2 = "##\n## "
        if (st == "s" && $3 == '$MOAB_JOBID') {
          sess = $1
          token = $3
          sessln = $0
        }
        if (st == "i" && $3 == sess) {
          inst = $1
          bytes = $4
          nodes = $5
          instln = $0
        } 
        if (st == "c" && $3 == inst) {
          conf = $1
          confln = $0
        }
        if (st == "r" && $3 == sess) {
          reg = $1
          regln = $0
        }
        if (st == "a" && $3 == sess) {
          act = $1
          actln = $0
        }
        if (st == "f" && $3 == inst) {
          frags = frags nl $0
          nodelist = nodelist " " $5
        }
        print $0
      }
      END {
        print nl "This job:"
        print nl2 sesshdr nl sessln
        print nl2 insthdr nl instln
        print nl2 confhdr nl confln
        print nl2 reghdr  nl regln
        print nl2 acthdr  nl actln
        print nl2 fraghdr nl substr(frags, 5) 
        print nl2 "sess: " sess "  token: " token "  inst: " inst "  bytes: " bytes "  nodes: " nodes
        print nl2 "dw_nodes:" nodelist
        print   
      } 
    '
    . $MODULESHOME/init/bash
    module load dws
    echo ""
    cmd "dwstat all | awk \"\$c\""
  fi
  if [[ -n $SLURM_JOB_ID ]]; then
    set | egrep "^SLURM|^DW|^HOST|^HIO|^OSTYPE|^LD_LIBRARY_PATH"
    job_dir="/$SLURM_JOB_ID"
  fi
  # Add .lib dir to library path
  build=${BUILD_TREE:=$PWD/..}
  libs=$build/src/.libs

  # Load module environment recorded at build
  mod_script="hiobuild.modules.bash"
  if [[ -e $BUILD_TREE/$mod_script ]]; then . $BUILD_TREE/$mod_script; fi

  if   [[ ${OSTYPE:0:6} == "darwin" ]]; then export DYLD_LIBRARY_PATH=$libs:$DYLD_LIBRARY_PATH
  elif [[ ${OSTYPE:0:5} == "linux" ]];  then export LD_LIBRARY_PATH=$libs:$LD_LIBRARY_PATH
  else errx "OSTYPE \"$OSTYPE\" not recognized"; fi

  export HIO_TEST_MI_SHIFT=$((ppn * tpp))
  export HIO_TEST_XEXEC=${HIO_TEST_XEXEC="./xexec/.libs/xexec.x"}

  addifd() {
    if [[ $root_count -lt 2 && -d $1 ]]; then
      HIO_TEST_ROOTS="$HIO_TEST_ROOTS,posix:$1/hio_test$job_dir"
      root_count=$(($root_count + 1))
    fi
  }

  # If HIO_TEST_ROOTS not set, set up default
  if [[ -z $HIO_TEST_ROOTS ]]; then

    if [[ $dw_alloc_mode -eq 1 ]]; then
      if [[ -z $HIO_datawarp_root ]]; then
        if [[ $hostpre == "tt-" ]]; then
          # Late DW Ph 1 - location of manually allocated BB directory
          export HIO_datawarp_root="/tmp/dw_scr"
        else
          synexit "dw_alloc_mode=1 and HIO_datawarp_root not set"
        fi
      fi
      # HIO_datawarp_root set, add LOGNAME and job_dir if needed
      if [[ ${HIO_datawarp_root/$LOGNAME} == $HIO_datawarp_root ]]; then
        HIO_datawarp_root="$HIO_datawarp_root/$LOGNAME"
      fi
      if [[ -n $job_dir && ${HIO_datawarp_root/$job_dir} == $HIO_datawarp_root ]]; then
        HIO_datawarp_root="$HIO_datawarp_root$job_dir"
      fi
    fi

    root_count=0;
    if [[ $dw_alloc_mode -ge 1 ]]; then
      HIO_TEST_ROOTS="DataWarp"
      root_count=$(($root_count + 1))
    fi

    if [[ $dw_alloc_mode -le 2 ]]; then
      addifd "/lus/snx11004/$LOGNAME"
      addifd "/lscratch1/$LOGNAME"
      addifd "/lscratch2/$LOGNAME"
      addifd "/lscratch3/$LOGNAME"
      addifd "/lscratch4/$LOGNAME"
      addifd "/lustre/scratch3/$LOGNAME"
      addifd "/lustre/scratch4/$LOGNAME"
      addifd "/lustre/scratch5/$LOGNAME"
      addifd "/lustre/tr2scratch1/$LOGNAME"
      addifd "/lustre/trscratch1/$LOGNAME"
      addifd "/lustre/trscratch2/$LOGNAME"
      addifd "/lustre/ttscratch1/$LOGNAME"
      addifd "/scratch1/$LOGNAME"
      addifd "/scratch1/users/$LOGNAME"
      addifd "/lustre/scratch1/yellow/$LOGNAME"
      addifd "$HOME/scratch-tmp"
    fi
    if [[ ${HIO_TEST_ROOTS:0:1} == "," ]]; then HIO_TEST_ROOTS=${HIO_TEST_ROOTS:1}; fi
  fi

  if [[ -z $HIO_TEST_ROOTS ]] ; then
    export HIO_TEST_ROOTS="posix:/tmp/hio_test"
    msg "Warning: HIO_TEST_ROOTS defaulted to $HIO_TEST_ROOTS"
  fi

  # Special hack for buffy - since no PFS, inhibit staging for sizes larger than tiny
  if [[ $hostpre == "bu-" && $size != "t" ]]; then
    msg "Buffy with size > tiny, disabling datawarp staging"
    export HIO_datawarp_stage_mode="disable"
  fi

  if [[ $query_size -eq 0 ]]; then
    # Display results of run_setup
    msg "                     Args: \"$args\""
    msg "                      PWD: \"$PWD\""
    msg "                    build: \"$build\""
    msg "                     libs: \"$libs\""
    msg "                   mpicmd: \"$mympicmd\""
    msg "      nodes/ranks/ppn/tpp: $nodes / $ranks / $ppn / $tpp"
    msg "                     size: \"$size\""
    msg "              totsz/blksz: $(cvt $totsz) / $(cvt $blksz)"
    msg "       nblk/nseg/nblkpseg: $(cvt $nblk) / $(cvt $nseg) / $(cvt $nblkpseg)"
    msg "   verbose/debug/dw_alloc: $verbose_lev / $debug_lev / $dw_alloc_mode"

    # Pretty print all HIO_ variables
    for var in ${!HIO_*} ${!XEXEC_*}; do
      msg "$(printf '%*s: "%s"' 25 $var ${!var})"
    done

  fi
fi


# --- end of run_setup ---
